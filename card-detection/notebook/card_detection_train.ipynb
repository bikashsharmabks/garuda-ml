{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count {features/labels}: 14/14\n",
      "Test count {features/labels}: 4/4\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import glob\n",
    "import numpy\n",
    "\n",
    "CLASSES = ['driving license', 'financial card', 'text']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "DATA_PATH = '../../data/card-detection/features/'\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 10\n",
    "IMG_WIDTH, IMG_HEIGHT = 256, 256\n",
    "\n",
    "MODEL_SAVE_PATH = '../../data/card-detection/models/card_detection_model_v1.h5'\n",
    "\n",
    "def data_prep():\n",
    "    features = [];\n",
    "    labels = [];\n",
    "    label_binarizer = preprocessing.LabelBinarizer()\n",
    "    label_binarizer.fit(CLASSES)\n",
    "    labels_one_hot = label_binarizer.transform(CLASSES)\n",
    "    \n",
    "    image_list = []\n",
    "    for filename in glob.glob(DATA_PATH + 'dl/*.png'):\n",
    "        image = load_img(filename, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "        image = img_to_array(image)\n",
    "        #image = image.reshape(image.shape[1], image.shape[2],image.shape[0])\n",
    "        image /= 255\n",
    "        features.append(image)\n",
    "        labels.append(labels_one_hot[0])\n",
    "    \n",
    "    for filename in glob.glob(DATA_PATH + 'cc/*.png'):\n",
    "        image = load_img(filename, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "        image = img_to_array(image)\n",
    "        #image = image.reshape(image.shape[1], image.shape[2],image.shape[0])\n",
    "        image /= 255\n",
    "        features.append(image)\n",
    "        labels.append(labels_one_hot[1])\n",
    "    \n",
    "    for filename in glob.glob(DATA_PATH + 'text/*.png'):\n",
    "        image = load_img(filename, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "        image = img_to_array(image)\n",
    "        #image = image.reshape(image.shape[1], image.shape[2],image.shape[0])\n",
    "        image /= 255\n",
    "        features.append(image)\n",
    "        labels.append(labels_one_hot[2])\n",
    "   \n",
    "    features = numpy.array(features)\n",
    "    #print(features.shape)\n",
    "    labels = numpy.array(labels)\n",
    "    #print(labels)\n",
    "  \n",
    "    return (features, labels)\n",
    "\n",
    "\n",
    "def load_data_fn(features, labels, test_size=0.2):\n",
    "    return train_test_split(features, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "\n",
    "#Initiate the train and test generators with data Augumentation \n",
    "# train_datagen = ImageDataGenerator(\n",
    "#   rescale = 1./255,\n",
    "#   horizontal_flip = True,\n",
    "#   fill_mode = \"nearest\",\n",
    "#   zoom_range = 0.3,\n",
    "#   width_shift_range = 0.3,\n",
    "#   height_shift_range=0.3,\n",
    "#   rotation_range=30)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(\n",
    "#   rescale = 1./255,\n",
    "#   horizontal_flip = True,\n",
    "#   fill_mode = \"nearest\",\n",
    "#   zoom_range = 0.3,\n",
    "#   width_shift_range = 0.3,\n",
    "#   height_shift_range=0.3,\n",
    "#   rotation_range=30)\n",
    "\n",
    "features, labels = data_prep()\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = load_data_fn(features, labels)\n",
    "print(\"Train count {features/labels}: %s/%s\" % (len(train_features), len(train_labels)))\n",
    "print(\"Test count {features/labels}: %s/%s\" % (len(test_features), len(test_labels)))\n",
    "\n",
    "# train_datagen.fit(train_features)\n",
    "# test_datagen.fit(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    initial_model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "  \n",
    "    #freeze initial layers, only utilise w and b \n",
    "    for layer in initial_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = initial_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    predictions = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "    # creating the final model \n",
    "    final_model = Model(input = initial_model.input, output = predictions)\n",
    "\n",
    "    # compile the model \n",
    "    final_model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "  \n",
    "    #final_model.summary()\n",
    "    return final_model\n",
    "\n",
    "\n",
    "def predict_fn(model, labels, image_path):\n",
    "    features_predict= []\n",
    "    image = load_img(image_path, target_size=(256, 256))\n",
    "    %matplotlib inline\n",
    "    imshow(image)\n",
    "    image = img_to_array(image)\n",
    "    image /= 255\n",
    "    features_predict.append(image)\n",
    "    features_predict = numpy.array(features_predict)\n",
    "  \n",
    "    prediction = model.predict(features_predict)\n",
    "    \n",
    "    predicted_label = CLASSES[numpy.argmax(prediction[0])]\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 1.1958 - acc: 0.4286\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.7896 - acc: 0.6429\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.7267 - acc: 0.6429\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.4312 - acc: 0.7143\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.2188 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.3334 - acc: 0.8571\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.5775 - acc: 0.7143\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.6362 - acc: 0.6429\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.1645 - acc: 0.9286\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1304 - acc: 1.0000\n",
      "4/4 [==============================] - 4s 907ms/step\n",
      "Loss : 0.10923025012016296   Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "#model.fit_generator(train_datagen.flow(train_features, train_labels),epochs=EPOCHS)\n",
    "\n",
    "model.fit(train_features, train_labels, batch_size=1, epochs=EPOCHS)\n",
    "\n",
    "#evaluate the model on test set\n",
    "loss, accuracy = model.evaluate(test_features, test_labels)\n",
    "print(\"Loss : %s   Accuracy: %s\" % (loss, accuracy))\n",
    "\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "del model\n",
    "\n",
    "model = load_model(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = DATA_PATH + 'test_8.png'\n",
    "predicted_label = predict_fn(model, labels, image_path)\n",
    " \n",
    "print(\"\\npredicted class: %s\" % (predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
