{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n",
      "Eager execution: True\n",
      "Count for data: 22709\n",
      "5402 5402 {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25} 62\n",
      "Train count {features/labels}: 4861/4861\n",
      "Test count {features/labels}: 541/541\n",
      "<BatchDataset shapes: ((?, 30), (?,)), types: (tf.int32, tf.int32)>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 30, 30)            3000      \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 100)               52400     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 55,501\n",
      "Trainable params: 55,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "4861/4861 [==============================] - 45s 9ms/step - loss: 0.6806 - acc: 0.5612\n",
      "Epoch 2/5\n",
      "4861/4861 [==============================] - 44s 9ms/step - loss: 0.5548 - acc: 0.7381\n",
      "Epoch 3/5\n",
      "4861/4861 [==============================] - 44s 9ms/step - loss: 0.5239 - acc: 0.7605\n",
      "Epoch 4/5\n",
      "4861/4861 [==============================] - 44s 9ms/step - loss: 0.5115 - acc: 0.7667\n",
      "Epoch 5/5\n",
      "4861/4861 [==============================] - 44s 9ms/step - loss: 0.5034 - acc: 0.7702\n",
      "541/541 [==============================] - 1s 3ms/step\n",
      "Loss : 0.4999419115277183   Accuracy: 0.7837338276799637\n",
      "\n",
      "name: Garrett Mitchell \n",
      "predicted class: ('male', 0.674123)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import preprocessing, cross_validation\n",
    "from sklearn import preprocessing, cross_validation\n",
    "import numpy as np\n",
    "\n",
    "data_path = '../data/gender-classification/features/gender_data.csv'\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "\n",
    "COLUMN_NAMES = ['name','gender']\n",
    "\n",
    "CLASSES = ['female', 'male']\n",
    "\n",
    "WORD_DICT = 'abcdefghijklmnopqrstuvwxyz';\n",
    "MAX_VOCABULARY_SIZE = len(WORD_DICT);\n",
    "\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 5\n",
    "max_feature_length = 30\n",
    "\n",
    "MODEL_SAVE_PATH = \"../models/gender_prediction\"\n",
    "    \n",
    "char_to_ix = { ch:i for i,ch in enumerate(WORD_DICT)}\n",
    "ix_to_char = { i:ch for i, ch in enumerate(WORD_DICT)}\n",
    "\n",
    "\n",
    "def raw_data_fn():\n",
    "    features = [];\n",
    "    labels = [];\n",
    "    \n",
    "    data = pd.read_csv(data_path, header=0)\n",
    "    \n",
    "    #drop all df with value NaN\n",
    "    data = data.dropna(subset=['name', 'gender'])\n",
    "    \n",
    "    #count total data\n",
    "    print(\"Count for data: %s\" % len(data))\n",
    "    \n",
    "    #get name \n",
    "    names = data['name'].astype(str);  \n",
    "    #print(name_description)\n",
    "    \n",
    "    #get labels \n",
    "    classes = data['gender']\n",
    "    ng_data = {};\n",
    "    for index, row in data.iterrows():\n",
    "        fullName = str(row['name']).split(\" \");\n",
    "        if(len(fullName)==3):\n",
    "            ng_data[fullName[2]] = row['gender'] \n",
    "        else:\n",
    "            ng_data[fullName[0]] = row['gender']     \n",
    "\n",
    "    non_eng_names = [] \n",
    "    for k,v in ng_data.items():\n",
    "\n",
    "        vector_for_char = [] \n",
    "    \n",
    "        for s in list(k):\n",
    "            if(s.lower() in WORD_DICT):\n",
    "                vector_for_char.append(char_to_ix[s.lower()])\n",
    "    \n",
    "        if(len(k) == len(vector_for_char)):  \n",
    "            features.append(vector_for_char); \n",
    "        \n",
    "            if(v.lower() == 'm'):\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)   \n",
    "        else:  \n",
    "            non_eng_names.append(k) \n",
    "     \n",
    "    features = tf.keras.preprocessing.sequence.pad_sequences(features, maxlen=max_feature_length)        \n",
    "    \n",
    "    print(len(labels),len(features),char_to_ix,len(non_eng_names))  \n",
    "\n",
    "       \n",
    "    return (features, labels)\n",
    "\n",
    "def load_data_fn(features, labels, test_size=0.1):\n",
    "    return cross_validation.train_test_split(features, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features,labels))\n",
    "    \n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def model_fn():\n",
    "    # create the model\n",
    "    embedding_vecor_length = 30\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(100, embedding_vecor_length, input_length=max_feature_length))\n",
    "    model.add(tf.keras.layers.LSTM(100))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001,name='RMS')\n",
    "\n",
    "    # We will now compile and print out a summary of our model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def predict_fn(model, name):\n",
    "    name_vec = []\n",
    "    for s in list(name):\n",
    "        if(s.lower() in WORD_DICT):\n",
    "            name_vec.append(char_to_ix[s.lower()]);\n",
    "        else:\n",
    "            name_vec.append(0);\n",
    "    name_vec = tf.keras.preprocessing.sequence.pad_sequences([name_vec], maxlen=max_feature_length)    \n",
    "    proba = model.predict_proba(name_vec);\n",
    "    predicted_label = model.predict_classes(name_vec)\n",
    "    return (CLASSES[predicted_label[0][0]] , proba[0][0] );\n",
    "    \n",
    "\n",
    "    \n",
    "features, labels = raw_data_fn()\n",
    "#print(features[0])\n",
    "#print(labels[0])\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = load_data_fn(features, labels)\n",
    "print(\"Train count {features/labels}: %s/%s\" % (len(train_features), len(train_labels)))\n",
    "print(\"Test count {features/labels}: %s/%s\" % (len(test_features), len(test_labels)))\n",
    "\n",
    "train_dataset = train_input_fn(train_features, train_labels, BATCH_SIZE)\n",
    "print(train_dataset)\n",
    "\n",
    "# #create a model for training\n",
    "model = model_fn()\n",
    "\n",
    "# #train the training set with model\n",
    "model.fit(train_features, train_labels, epochs=EPOCHS)\n",
    "\n",
    "# #evaluate the model on test set\n",
    "loss, accuracy = model.evaluate(test_features, test_labels)\n",
    "print(\"Loss : %s   Accuracy: %s\" % (loss, accuracy))\n",
    "\n",
    "name = \"Garrett Mitchell\"\n",
    "\n",
    "predicted_label = predict_fn(model, name)\n",
    "print(\"\\nname: %s \\npredicted class: %s\" % (name , predicted_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    \"gender_prediction\",\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'gender_prediction', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d1a75f67a83d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m gender_pred_model = tf.keras.models.load_model(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m\"gender_prediction\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSPropOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RMS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgender_pred_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;31m# instantiate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'gender_prediction', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "gender_pred_model = tf.keras.models.load_model(\n",
    "    \"gender_prediction\"\n",
    ")\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001,name='RMS')\n",
    "gender_pred_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "name = \"Aashish\"\n",
    "predicted_label,prob = predict_fn(gender_pred_model, name)\n",
    "print(\"\\nname: %s  \\npredicted class: %s \\n proba : %s\" % (name, predicted_label,prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "WORD_DICT = 'abcdefghijklmnopqrstuvwxyz';\n",
    "char_to_ix = { ch:i for i,ch in enumerate(WORD_DICT)}\n",
    "max_feature_length = 30\n",
    "\n",
    "class Predicition:\n",
    "    def __init__(self):\n",
    "        gender_pred_model = tf.keras.models.load_model(\"model/gender_prediction\");\n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001, name='RMS')\n",
    "        gender_pred_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_accuracy'])\n",
    "        self.gender_pred_model = gender_pred_model\n",
    "   \n",
    "    def predict_gender(name):\n",
    "        name_vec = []\n",
    "        for s in list(name):\n",
    "            if(s.lower() in WORD_DICT):\n",
    "                    name_vec.append(char_to_ix[s.lower()])\n",
    "            else:\n",
    "                 name_vec.append(0)\n",
    "\n",
    "        name_vec = tf.keras.preprocessing.sequence.pad_sequences([name_vec], maxlen=max_feature_length)    \n",
    "        proba = self.gender_pred_model.predict_proba(name_vec);\n",
    "        predicted_label = self.gender_pred_model.predict_classes(name_vec)\n",
    "        return (CLASSES[predicted_label[0][0]] , proba[0][0]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
