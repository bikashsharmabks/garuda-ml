{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n",
      "Eager execution: True\n",
      "Count for data: 63\n",
      "Train count {features/labels}: 50/50\n",
      "Test count {features/labels}: 13/13\n",
      "<BatchDataset shapes: ((?, 1000), (?, 4)), types: (tf.float64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, cross_validation\n",
    "\n",
    "data_path = '/data/users-csv.csv'\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "\n",
    "COLUMN_NAMES = ['screen_name','name','description', 'class']\n",
    "\n",
    "CLASSES = ['sports','technology','entertainment', 'politics',\n",
    "           'music','legal','medical','education','journalism']\n",
    "\n",
    "num_labels = len(CLASSES)\n",
    "VOCAB_SIZE = 1000\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 5\n",
    "\n",
    "def raw_data_fn(y_name='class'):\n",
    "    data = pd.read_csv(data_path, header=0)\n",
    "    \n",
    "    #drop all df with value NaN\n",
    "    data = data.dropna(subset=['name', 'description', 'class'])\n",
    "    \n",
    "    #count total data\n",
    "    print(\"Count for data: %s\" % len(data))\n",
    "    \n",
    "    #append name and description\n",
    "    name_description = data['name'].astype(str) + ' ' + data['description']   \n",
    "   \n",
    "    #get labels \n",
    "    classes = data['class']\n",
    "\n",
    "    # define Tokenizer with Vocab Size\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE)\n",
    "    tokenizer.fit_on_texts(name_description)\n",
    "    \n",
    "    # define encoder and make labels\n",
    "    encoder = preprocessing.LabelBinarizer()\n",
    "    encoder.fit(classes)\n",
    "    \n",
    "    #make features and labels\n",
    "    labels = encoder.transform(classes)\n",
    "    features = tokenizer.texts_to_matrix(name_description, mode='tfidf')\n",
    "       \n",
    "    return (features, labels)\n",
    "\n",
    "def load_data_fn(features, labels, test_size=0.2):\n",
    "    return cross_validation.train_test_split(features, labels, test_size=test_size, random_state=42)\n",
    "   \n",
    "\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features,labels))\n",
    "    \n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "features, labels = raw_data_fn()\n",
    "#print(features[0])\n",
    "#print(labels[0])\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = load_data_fn(features, labels)\n",
    "print(\"Train count {features/labels}: %s/%s\" % (len(train_features), len(train_labels)))\n",
    "print(\"Test count {features/labels}: %s/%s\" % (len(test_features), len(test_labels)))\n",
    "\n",
    "train_dataset = train_input_fn(train_features, train_labels, BATCH_SIZE)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
